{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dive Deep into Question Answering (QA)\n",
    "\n",
    "Question answering (QA) task reflects capabilities of reading comprehension. For example, the Stanford Question Answering Dataset (SQuAD v1.1) consists of reading passages and questions, where the answer to every question is just a segment of text (text span) from the passage that the question is about [Rajpurkar et al., 2016]. \n",
    "\n",
    "Consider a passage “Some experts report that a mask’s efficacy is inconclusive. However, mask makers insist that their products, such as N95 respirator masks, can guard against the virus.” and a question “Who say that N95 respirator masks can guard against the virus?”. The answer should be the text span “mask makers” in the passage. Thus, the goal in SQuAD v1.1 is to predict the start and end of the text span in the passage given a pair of question and passage.\n",
    "\n",
    "![Fine-tuning BERT for question answering.](https://d2l.ai/_images/bert-qa.svg)\n",
    "\n",
    "\n",
    "To fine-tune BERT for question answering, the question and passage are packed as the first and second text sequence, respectively, in the input of BERT. To predict the position of the start of the text span, the same additional fully-connected layer will transform the BERT representation of any token from the passage of position $i$ into a scalar score $s_i$. Such scores of all the passage tokens are further transformed by the softmax operation into a probability distribution, so that each token position $i$ in the passage is assigned a probability $p_i$ of being the start of the text span. Predicting the end of the text span is the same as above, except that parameters in its additional fully-connected layer are independent from those for predicting the start. When predicting the end, any passage token of position $i$ is transformed by the same fully-connected layer into a scalar score $e_i$. :numref:fig_bert-qa depicts fine-tuning BERT for question answering.\n",
    "\n",
    "For question answering, the supervised learning’s training objective is as straightforward as maximizing the log-likelihoods of the ground-truth start and end positions. When predicting the span, we can compute the score $s_i + e_j$ for a valid span from position $i$ to position $j$ (where $i \\leq j$), and output the span with the highest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset for squad...\n",
      "--2020-08-22 20:55:12--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\n",
      "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.110.153, 185.199.111.153, 185.199.108.153, ...\n",
      "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.110.153|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 30288272 (29M) [application/json]\n",
      "Saving to: ‘v1.1/train-v1.1.json’\n",
      "\n",
      "v1.1/train-v1.1.jso 100%[===================>]  28.88M   187MB/s    in 0.2s    \n",
      "\n",
      "2020-08-22 20:55:13 (187 MB/s) - ‘v1.1/train-v1.1.json’ saved [30288272/30288272]\n",
      "\n",
      "--2020-08-22 20:55:13--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\n",
      "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.109.153, 185.199.110.153, 185.199.111.153, ...\n",
      "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.109.153|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4854279 (4.6M) [application/json]\n",
      "Saving to: ‘v1.1/dev-v1.1.json’\n",
      "\n",
      "v1.1/dev-v1.1.json  100%[===================>]   4.63M  --.-KB/s    in 0.05s   \n",
      "\n",
      "2020-08-22 20:55:13 (88.2 MB/s) - ‘v1.1/dev-v1.1.json’ saved [4854279/4854279]\n",
      "\n",
      "--2020-08-22 20:55:13--  https://worksheets.codalab.org/rest/bundles/0xbcd57bee090b421c982906709c8c27e1/contents/blob/\n",
      "Resolving worksheets.codalab.org (worksheets.codalab.org)... 40.114.41.203\n",
      "Connecting to worksheets.codalab.org (worksheets.codalab.org)|40.114.41.203|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Syntax error in Set-Cookie: codalab_session=\"\"; expires=Thu, 01 Jan 1970 00:00:00 GMT; Max-Age=-1; Path=/ at position 70.\n",
      "Length: unspecified [text/x-python]\n",
      "Saving to: ‘v1.1/evaluate-v1.1.py’\n",
      "\n",
      "v1.1/evaluate-v1.1.     [ <=>                ]   3.34K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-08-22 20:55:13 (287 MB/s) - ‘v1.1/evaluate-v1.1.py’ saved [3419]\n",
      "\n",
      "--2020-08-22 20:55:13--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
      "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
      "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 42123633 (40M) [application/json]\n",
      "Saving to: ‘v2.0/train-v2.0.json’\n",
      "\n",
      "v2.0/train-v2.0.jso 100%[===================>]  40.17M   171MB/s    in 0.2s    \n",
      "\n",
      "2020-08-22 20:55:13 (171 MB/s) - ‘v2.0/train-v2.0.json’ saved [42123633/42123633]\n",
      "\n",
      "--2020-08-22 20:55:13--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
      "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.111.153, 185.199.108.153, 185.199.109.153, ...\n",
      "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.111.153|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4370528 (4.2M) [application/json]\n",
      "Saving to: ‘v2.0/dev-v2.0.json’\n",
      "\n",
      "v2.0/dev-v2.0.json  100%[===================>]   4.17M  --.-KB/s    in 0.07s   \n",
      "\n",
      "2020-08-22 20:55:14 (62.2 MB/s) - ‘v2.0/dev-v2.0.json’ saved [4370528/4370528]\n",
      "\n",
      "--2020-08-22 20:55:14--  https://worksheets.codalab.org/rest/bundles/0x6b567e1cf2e041ec80d7098f031c5c9e/contents/blob/\n",
      "Resolving worksheets.codalab.org (worksheets.codalab.org)... 40.114.41.203\n",
      "Connecting to worksheets.codalab.org (worksheets.codalab.org)|40.114.41.203|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Syntax error in Set-Cookie: codalab_session=\"\"; expires=Thu, 01 Jan 1970 00:00:00 GMT; Max-Age=-1; Path=/ at position 70.\n",
      "Length: unspecified [text/x-python]\n",
      "Saving to: ‘v2.0/evaluate-v2.0.py’\n",
      "\n",
      "v2.0/evaluate-v2.0.     [ <=>                ]  10.30K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-08-22 20:55:14 (191 MB/s) - ‘v2.0/evaluate-v2.0.py’ saved [10547]\n",
      "\n",
      "Squad data download done!\n",
      "Verifying Dataset....\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "## Download SQuAD v1.1 and v2.0\n",
    "!bash ./data/squad/squad_download.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, time\n",
    "\n",
    "# Hyperparameters\n",
    "parser = argparse.ArgumentParser('BERT finetuning')\n",
    "parser.add_argument('--train_file', default=\"./data/squad/v1.1/train-v1.1.json\")\n",
    "parser.add_argument('--vocab_file', default='vocab')\n",
    "\n",
    "parser.add_argument('--version_2_with_negative', default=False)\n",
    "parser.add_argument('--do_lower_case', default=True)\n",
    "parser.add_argument(\"--max_seq_length\", default=384, type=int, \n",
    "                    help=\"The maximum total input sequence length after WordPiece tokenization\")\n",
    "parser.add_argument(\"--doc_stride\", default=128, type=int,\n",
    "                    help=\"When splitting up a long document into chunks, how much stride to take between chunks.\")\n",
    "parser.add_argument(\"--max_query_length\", default=64, type=int,\n",
    "                    help=\"The maximum number of tokens for the question. Questions longer than this will \"\n",
    "                         \"be truncated to this length.\")\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read SQuAD examples\n",
    "\n",
    "We first read SQuAD examples from the input file. Here we read SQuAD v1.1. Each example will be in the format of `SquadExample`. The `SquadExample` class contains the below features:\n",
    "\n",
    "- qas_id: the ID for SQuAD\n",
    "- question_text: the original question string\n",
    "- doc_tokens: the tokenized context (a list of string)\n",
    "- orig_answer_text: the original answer string\n",
    "- start_position: the start position of the answer in the given raw context\n",
    "- end_position: the end position of the answer in the given raw context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections, json\n",
    "from tokenization import BertTokenizer, whitespace_tokenize\n",
    "\n",
    "class SquadExample(object):\n",
    "    \"\"\"\n",
    "    A single training/test example for the Squad dataset.\n",
    "    For examples without an answer, the start and end position are -1.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 qas_id,\n",
    "                 question_text,\n",
    "                 doc_tokens,\n",
    "                 orig_answer_text=None,\n",
    "                 start_position=None,\n",
    "                 end_position=None,\n",
    "                 is_impossible=None):\n",
    "        self.qas_id = qas_id\n",
    "        self.question_text = question_text\n",
    "        self.doc_tokens = doc_tokens\n",
    "        self.orig_answer_text = orig_answer_text\n",
    "        self.start_position = start_position\n",
    "        self.end_position = end_position\n",
    "        self.is_impossible = is_impossible\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__repr__()\n",
    "\n",
    "    def __repr__(self):\n",
    "        s = \"\"\n",
    "        s += \"qas_id: %s\" % (self.qas_id)\n",
    "        s += \", question_text: %s\" % (\n",
    "            self.question_text)\n",
    "        s += \", doc_tokens: [%s]\" % (\" \".join(self.doc_tokens))\n",
    "        if self.start_position:\n",
    "            s += \", start_position: %d\" % (self.start_position)\n",
    "        if self.end_position:\n",
    "            s += \", end_position: %d\" % (self.end_position)\n",
    "        if self.is_impossible:\n",
    "            s += \", is_impossible: %r\" % (self.is_impossible)\n",
    "        return s\n",
    "        \n",
    "\n",
    "def read_squad_examples(input_file, is_training, version_2_with_negative):\n",
    "    \"\"\"Read a SQuAD json file into a list of SquadExample.\"\"\"\n",
    "    with open(input_file, \"r\", encoding='utf-8') as reader:\n",
    "        input_data = json.load(reader)[\"data\"]\n",
    "\n",
    "    def is_whitespace(c):\n",
    "        if c == \" \" or c == \"\\t\" or c == \"\\r\" or c == \"\\n\" or ord(c) == 0x202F:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    examples = []\n",
    "    for entry in input_data:\n",
    "        for paragraph in entry[\"paragraphs\"]:\n",
    "            paragraph_text = paragraph[\"context\"]\n",
    "            doc_tokens = []\n",
    "            char_to_word_offset = []\n",
    "            prev_is_whitespace = True\n",
    "            for c in paragraph_text:\n",
    "                if is_whitespace(c):\n",
    "                    prev_is_whitespace = True\n",
    "                else:\n",
    "                    if prev_is_whitespace:\n",
    "                        doc_tokens.append(c)\n",
    "                    else:\n",
    "                        doc_tokens[-1] += c\n",
    "                    prev_is_whitespace = False\n",
    "                char_to_word_offset.append(len(doc_tokens) - 1)\n",
    "\n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                qas_id = qa[\"id\"]\n",
    "                question_text = qa[\"question\"]\n",
    "                start_position = None\n",
    "                end_position = None\n",
    "                orig_answer_text = None\n",
    "                is_impossible = False\n",
    "                if is_training:\n",
    "                    if version_2_with_negative:\n",
    "                        is_impossible = qa[\"is_impossible\"]\n",
    "                    if (len(qa[\"answers\"]) != 1) and (not is_impossible):\n",
    "                        raise ValueError(\n",
    "                            \"For training, each question should have exactly 1 answer.\")\n",
    "                    if not is_impossible:\n",
    "                        answer = qa[\"answers\"][0]\n",
    "                        orig_answer_text = answer[\"text\"]\n",
    "                        answer_offset = answer[\"answer_start\"]\n",
    "                        answer_length = len(orig_answer_text)\n",
    "                        start_position = char_to_word_offset[answer_offset]\n",
    "                        end_position = char_to_word_offset[answer_offset + answer_length - 1]\n",
    "                        # Only add answers where the text can be exactly recovered from the\n",
    "                        # document. If this CAN'T happen it's likely due to weird Unicode\n",
    "                        # stuff so we will just skip the example.\n",
    "                        #\n",
    "                        # Note that this means for training mode, every example is NOT\n",
    "                        # guaranteed to be preserved.\n",
    "                        actual_text = \" \".join(doc_tokens[start_position:(end_position + 1)])\n",
    "                        cleaned_answer_text = \" \".join(\n",
    "                            whitespace_tokenize(orig_answer_text))\n",
    "                        if actual_text.find(cleaned_answer_text) == -1:\n",
    "                            logger.warning(\"Could not find answer: '%s' vs. '%s'\",\n",
    "                                           actual_text, cleaned_answer_text)\n",
    "                            continue\n",
    "                    else:\n",
    "                        start_position = -1\n",
    "                        end_position = -1\n",
    "                        orig_answer_text = \"\"\n",
    "\n",
    "                example = SquadExample(\n",
    "                    qas_id=qas_id,\n",
    "                    question_text=question_text,\n",
    "                    doc_tokens=doc_tokens,\n",
    "                    orig_answer_text=orig_answer_text,\n",
    "                    start_position=start_position,\n",
    "                    end_position=end_position,\n",
    "                    is_impossible=is_impossible)\n",
    "                examples.append(example)\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.22 s, sys: 150 ms, total: 8.37 s\n",
      "Wall time: 8.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_examples = read_squad_examples(input_file=args.train_file, \n",
    "                                     is_training=True,\n",
    "                                     version_2_with_negative=args.version_2_with_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's output the second train_example'scomponents as a demo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is in front of the Notre Dame Main Building?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples[1].question_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Architecturally,', 'the', 'school', 'has', 'a', 'Catholic', 'character.', 'Atop', 'the', 'Main', \"Building's\", 'gold', 'dome', 'is', 'a', 'golden', 'statue', 'of', 'the', 'Virgin', 'Mary.', 'Immediately', 'in', 'front', 'of', 'the', 'Main', 'Building', 'and', 'facing', 'it,', 'is', 'a', 'copper', 'statue', 'of', 'Christ', 'with', 'arms', 'upraised', 'with', 'the', 'legend', '\"Venite', 'Ad', 'Me', 'Omnes\".', 'Next', 'to', 'the', 'Main', 'Building', 'is', 'the', 'Basilica', 'of', 'the', 'Sacred', 'Heart.', 'Immediately', 'behind', 'the', 'basilica', 'is', 'the', 'Grotto,', 'a', 'Marian', 'place', 'of', 'prayer', 'and', 'reflection.', 'It', 'is', 'a', 'replica', 'of', 'the', 'grotto', 'at', 'Lourdes,', 'France', 'where', 'the', 'Virgin', 'Mary', 'reputedly', 'appeared', 'to', 'Saint', 'Bernadette', 'Soubirous', 'in', '1858.', 'At', 'the', 'end', 'of', 'the', 'main', 'drive', '(and', 'in', 'a', 'direct', 'line', 'that', 'connects', 'through', '3', 'statues', 'and', 'the', 'Gold', 'Dome),', 'is', 'a', 'simple,', 'modern', 'stone', 'statue', 'of', 'Mary.']\n"
     ]
    }
   ],
   "source": [
    "print(train_examples[1].doc_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a copper statue of Christ'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples[1].orig_answer_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 36)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples[1].start_position, train_examples[1].end_position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to SQuAD features\n",
    "\n",
    "Let's convert the training examples (`SquadExample`) using `convert_examples_to_features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, tokenizer, max_seq_length,\n",
    "                                 doc_stride, max_query_length, is_training):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "\n",
    "    unique_id = 1000000000\n",
    "\n",
    "    features = []\n",
    "    for (example_index, example) in enumerate(examples):\n",
    "        query_tokens = tokenizer.tokenize(example.question_text)\n",
    "\n",
    "        if len(query_tokens) > max_query_length:\n",
    "            query_tokens = query_tokens[0:max_query_length]\n",
    "\n",
    "        tok_to_orig_index = []\n",
    "        orig_to_tok_index = []\n",
    "        all_doc_tokens = []\n",
    "        for (i, token) in enumerate(example.doc_tokens):\n",
    "            orig_to_tok_index.append(len(all_doc_tokens))\n",
    "            sub_tokens = tokenizer.tokenize(token)\n",
    "            for sub_token in sub_tokens:\n",
    "                tok_to_orig_index.append(i)\n",
    "                all_doc_tokens.append(sub_token)\n",
    "\n",
    "        tok_start_position = None\n",
    "        tok_end_position = None\n",
    "        if is_training and example.is_impossible:\n",
    "            tok_start_position = -1\n",
    "            tok_end_position = -1\n",
    "        if is_training and not example.is_impossible:\n",
    "            tok_start_position = orig_to_tok_index[example.start_position]\n",
    "            if example.end_position < len(example.doc_tokens) - 1:\n",
    "                tok_end_position = orig_to_tok_index[example.end_position + 1] - 1\n",
    "            else:\n",
    "                tok_end_position = len(all_doc_tokens) - 1\n",
    "            (tok_start_position, tok_end_position) = _improve_answer_span(\n",
    "                all_doc_tokens, tok_start_position, tok_end_position, tokenizer,\n",
    "                example.orig_answer_text)\n",
    "\n",
    "        # The -3 accounts for [CLS], [SEP] and [SEP]\n",
    "        max_tokens_for_doc = max_seq_length - len(query_tokens) - 3\n",
    "\n",
    "        # We can have documents that are longer than the maximum sequence length.\n",
    "        # To deal with this we do a sliding window approach, where we take chunks\n",
    "        # of the up to our max length with a stride of `doc_stride`.\n",
    "        _DocSpan = collections.namedtuple(  # pylint: disable=invalid-name\n",
    "            \"DocSpan\", [\"start\", \"length\"])\n",
    "        doc_spans = []\n",
    "        start_offset = 0\n",
    "        while start_offset < len(all_doc_tokens):\n",
    "            length = len(all_doc_tokens) - start_offset\n",
    "            if length > max_tokens_for_doc:\n",
    "                length = max_tokens_for_doc\n",
    "            doc_spans.append(_DocSpan(start=start_offset, length=length))\n",
    "            if start_offset + length == len(all_doc_tokens):\n",
    "                break\n",
    "            start_offset += min(length, doc_stride)\n",
    "\n",
    "        for (doc_span_index, doc_span) in enumerate(doc_spans):\n",
    "            tokens = []\n",
    "            token_to_orig_map = {}\n",
    "            token_is_max_context = {}\n",
    "            segment_ids = []\n",
    "            tokens.append(\"[CLS]\")\n",
    "            segment_ids.append(0)\n",
    "            for token in query_tokens:\n",
    "                tokens.append(token)\n",
    "                segment_ids.append(0)\n",
    "            tokens.append(\"[SEP]\")\n",
    "            segment_ids.append(0)\n",
    "\n",
    "            for i in range(doc_span.length):\n",
    "                split_token_index = doc_span.start + i\n",
    "                token_to_orig_map[len(tokens)] = tok_to_orig_index[split_token_index]\n",
    "\n",
    "                is_max_context = _check_is_max_context(doc_spans, doc_span_index,\n",
    "                                                       split_token_index)\n",
    "                token_is_max_context[len(tokens)] = is_max_context\n",
    "                tokens.append(all_doc_tokens[split_token_index])\n",
    "                segment_ids.append(1)\n",
    "            tokens.append(\"[SEP]\")\n",
    "            segment_ids.append(1)\n",
    "\n",
    "            input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "            # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "            # tokens are attended to.\n",
    "            input_mask = [1] * len(input_ids)\n",
    "\n",
    "            # Zero-pad up to the sequence length.\n",
    "            while len(input_ids) < max_seq_length:\n",
    "                input_ids.append(0)\n",
    "                input_mask.append(0)\n",
    "                segment_ids.append(0)\n",
    "\n",
    "            assert len(input_ids) == max_seq_length\n",
    "            assert len(input_mask) == max_seq_length\n",
    "            assert len(segment_ids) == max_seq_length\n",
    "\n",
    "            start_position = None\n",
    "            end_position = None\n",
    "            if is_training and not example.is_impossible:\n",
    "                # For training, if our document chunk does not contain an annotation\n",
    "                # we throw it out, since there is nothing to predict.\n",
    "                doc_start = doc_span.start\n",
    "                doc_end = doc_span.start + doc_span.length - 1\n",
    "                out_of_span = False\n",
    "                if not (tok_start_position >= doc_start and\n",
    "                        tok_end_position <= doc_end):\n",
    "                    out_of_span = True\n",
    "                if out_of_span:\n",
    "                    start_position = 0\n",
    "                    end_position = 0\n",
    "                else:\n",
    "                    doc_offset = len(query_tokens) + 2\n",
    "                    start_position = tok_start_position - doc_start + doc_offset\n",
    "                    end_position = tok_end_position - doc_start + doc_offset\n",
    "            if is_training and example.is_impossible:\n",
    "                start_position = 0\n",
    "                end_position = 0\n",
    "\n",
    "            features.append(\n",
    "                InputFeatures(\n",
    "                    unique_id=unique_id,\n",
    "                    example_index=example_index,\n",
    "                    doc_span_index=doc_span_index,\n",
    "                    tokens=tokens,\n",
    "                    token_to_orig_map=token_to_orig_map,\n",
    "                    token_is_max_context=token_is_max_context,\n",
    "                    input_ids=input_ids,\n",
    "                    input_mask=input_mask,\n",
    "                    segment_ids=segment_ids,\n",
    "                    start_position=start_position,\n",
    "                    end_position=end_position,\n",
    "                    is_impossible=example.is_impossible))\n",
    "            unique_id += 1\n",
    "\n",
    "    return features\n",
    "\n",
    "def _improve_answer_span(doc_tokens, input_start, input_end, tokenizer,\n",
    "                         orig_answer_text):\n",
    "    \"\"\"Returns tokenized answer spans that better match the annotated answer.\"\"\"\n",
    "\n",
    "    # The SQuAD annotations are character based. We first project them to\n",
    "    # whitespace-tokenized words. But then after WordPiece tokenization, we can\n",
    "    # often find a \"better match\". For example:\n",
    "    #\n",
    "    #   Question: What year was John Smith born?\n",
    "    #   Context: The leader was John Smith (1895-1943).\n",
    "    #   Answer: 1895\n",
    "    #\n",
    "    # The original whitespace-tokenized answer will be \"(1895-1943).\". However\n",
    "    # after tokenization, our tokens will be \"( 1895 - 1943 ) .\". So we can match\n",
    "    # the exact answer, 1895.\n",
    "    #\n",
    "    # However, this is not always possible. Consider the following:\n",
    "    #\n",
    "    #   Question: What country is the top exporter of electornics?\n",
    "    #   Context: The Japanese electronics industry is the lagest in the world.\n",
    "    #   Answer: Japan\n",
    "    #\n",
    "    # In this case, the annotator chose \"Japan\" as a character sub-span of\n",
    "    # the word \"Japanese\". Since our WordPiece tokenizer does not split\n",
    "    # \"Japanese\", we just use \"Japanese\" as the annotation. This is fairly rare\n",
    "    # in SQuAD, but does happen.\n",
    "    tok_answer_text = \" \".join(tokenizer.tokenize(orig_answer_text))\n",
    "\n",
    "    for new_start in range(input_start, input_end + 1):\n",
    "        for new_end in range(input_end, new_start - 1, -1):\n",
    "            text_span = \" \".join(doc_tokens[new_start:(new_end + 1)])\n",
    "            if text_span == tok_answer_text:\n",
    "                return (new_start, new_end)\n",
    "\n",
    "    return (input_start, input_end)\n",
    "\n",
    "def _check_is_max_context(doc_spans, cur_span_index, position):\n",
    "    \"\"\"Check if this is the 'max context' doc span for the token.\"\"\"\n",
    "\n",
    "    # Because of the sliding window approach taken to scoring documents, a single\n",
    "    # token can appear in multiple documents. E.g.\n",
    "    #  Doc: the man went to the store and bought a gallon of milk\n",
    "    #  Span A: the man went to the\n",
    "    #  Span B: to the store and bought\n",
    "    #  Span C: and bought a gallon of\n",
    "    #  ...\n",
    "    #\n",
    "    # Now the word 'bought' will have two scores from spans B and C. We only\n",
    "    # want to consider the score with \"maximum context\", which we define as\n",
    "    # the *minimum* of its left and right context (the *sum* of left and\n",
    "    # right context will always be the same, of course).\n",
    "    #\n",
    "    # In the example the maximum context for 'bought' would be span C since\n",
    "    # it has 1 left context and 3 right context, while span B has 4 left context\n",
    "    # and 0 right context.\n",
    "    best_score = None\n",
    "    best_span_index = None\n",
    "    for (span_index, doc_span) in enumerate(doc_spans):\n",
    "        end = doc_span.start + doc_span.length - 1\n",
    "        if position < doc_span.start:\n",
    "            continue\n",
    "        if position > end:\n",
    "            continue\n",
    "        num_left_context = position - doc_span.start\n",
    "        num_right_context = end - position\n",
    "        score = min(num_left_context, num_right_context) + 0.01 * doc_span.length\n",
    "        if best_score is None or score > best_score:\n",
    "            best_score = score\n",
    "            best_span_index = span_index\n",
    "\n",
    "    return cur_span_index == best_span_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each example's extracted features will be save into the `InputFeatures` format as defined below. It has the following components:\n",
    "\n",
    "- example_index: The ID for this exmaple;\n",
    "- tokens: The tokens after `BertTokenizer`;\n",
    "- token_to_orig_map: The index of new tokens mapping back to its original token index in `SquadExample.doc_tokens`;\n",
    "- token_is_max_context: The result of `_check_is_max_context`;\n",
    "- input_ids: The ID of each token after running through the tokenizer;\n",
    "- input_mask: The mask has 1 for real tokens and 0 for padding tokens;\n",
    "- segment_ids: A list of 0 and 1 to segment the question and context;\n",
    "- start_position: The start position of the answer in the processed `tokens`;\n",
    "- end_position: The end position of the answer in the processed `tokens`;\n",
    "- is_impossible: For SQuAD 2.0, it combines existing SQuAD data with over 50,000 unanswerable questions,\"is_impossible\" is the label for unanswerable questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 unique_id,\n",
    "                 example_index,\n",
    "                 doc_span_index,\n",
    "                 tokens,\n",
    "                 token_to_orig_map,\n",
    "                 token_is_max_context,\n",
    "                 input_ids,\n",
    "                 input_mask,\n",
    "                 segment_ids,\n",
    "                 start_position=None,\n",
    "                 end_position=None,\n",
    "                 is_impossible=None):\n",
    "        self.unique_id = unique_id\n",
    "        self.example_index = example_index\n",
    "        self.doc_span_index = doc_span_index\n",
    "        self.tokens = tokens\n",
    "        self.token_to_orig_map = token_to_orig_map\n",
    "        self.token_is_max_context = token_is_max_context\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.start_position = start_position\n",
    "        self.end_position = end_position\n",
    "        self.is_impossible = is_impossible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To exact the features of the full dataset, it will take some time. For sake of simplicity, we will exact the features of the first 100 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 500 ms, sys: 8 µs, total: 500 ms\n",
      "Wall time: 499 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "convert_examples = 100\n",
    "\n",
    "tokenizer = BertTokenizer(args.vocab_file, \n",
    "                          do_lower_case=args.do_lower_case, \n",
    "                          max_len=512)\n",
    "\n",
    "train_features = convert_examples_to_features(examples=train_examples[:convert_examples],\n",
    "                                              tokenizer=tokenizer,\n",
    "                                              max_seq_length=args.max_seq_length,\n",
    "                                              doc_stride=args.doc_stride,\n",
    "                                              max_query_length=args.max_query_length,\n",
    "                                              is_training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's output extracted feature of the second example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features[1].example_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'what', 'is', 'in', 'front', 'of', 'the', 'notre', 'dame', 'main', 'building', '?', '[SEP]', 'architectural', '##ly', ',', 'the', 'school', 'has', 'a', 'catholic', 'character', '.', 'atop', 'the', 'main', 'building', \"'\", 's', 'gold', 'dome', 'is', 'a', 'golden', 'statue', 'of', 'the', 'virgin', 'mary', '.', 'immediately', 'in', 'front', 'of', 'the', 'main', 'building', 'and', 'facing', 'it', ',', 'is', 'a', 'copper', 'statue', 'of', 'christ', 'with', 'arms', 'up', '##rai', '##sed', 'with', 'the', 'legend', '\"', 've', '##ni', '##te', 'ad', 'me', 'om', '##nes', '\"', '.', 'next', 'to', 'the', 'main', 'building', 'is', 'the', 'basilica', 'of', 'the', 'sacred', 'heart', '.', 'immediately', 'behind', 'the', 'basilica', 'is', 'the', 'gr', '##otto', ',', 'a', 'marian', 'place', 'of', 'prayer', 'and', 'reflection', '.', 'it', 'is', 'a', 'replica', 'of', 'the', 'gr', '##otto', 'at', 'lou', '##rdes', ',', 'france', 'where', 'the', 'virgin', 'mary', 'reputed', '##ly', 'appeared', 'to', 'saint', 'bern', '##ade', '##tte', 'so', '##ub', '##iro', '##us', 'in', '1858', '.', 'at', 'the', 'end', 'of', 'the', 'main', 'drive', '(', 'and', 'in', 'a', 'direct', 'line', 'that', 'connects', 'through', '3', 'statues', 'and', 'the', 'gold', 'dome', ')', ',', 'is', 'a', 'simple', ',', 'modern', 'stone', 'statue', 'of', 'mary', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(train_features[1].tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `token_to_orig_map` will map the new tokens to its original tokens. For example, as we can use below, the new tokens with index 13, 14, 15 can be mapped back the original token index 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features[1].token_to_orig_map[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('architectural', '##ly', ',')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features[1].tokens[13], train_features[1].tokens[14], train_features[1].tokens[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Architecturally,'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples[1].doc_tokens[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look of the rest of components of our features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2054, 2003, 1999, 2392, 1997, 1996, 10289, 8214, 2364, 2311, 1029, 102, 6549, 2135, 1010, 1996, 2082, 2038, 1037, 3234, 2839, 1012, 10234, 1996, 2364, 2311, 1005, 1055, 2751, 8514, 2003, 1037, 3585, 6231, 1997, 1996, 6261, 2984, 1012, 3202, 1999, 2392, 1997, 1996, 2364, 2311, 1998, 5307, 2009, 1010, 2003, 1037, 6967, 6231, 1997, 4828, 2007, 2608, 2039, 14995, 6924, 2007, 1996, 5722, 1000, 2310, 3490, 2618, 4748, 2033, 18168, 5267, 1000, 1012, 2279, 2000, 1996, 2364, 2311, 2003, 1996, 13546, 1997, 1996, 6730, 2540, 1012, 3202, 2369, 1996, 13546, 2003, 1996, 24665, 23052, 1010, 1037, 14042, 2173, 1997, 7083, 1998, 9185, 1012, 2009, 2003, 1037, 15059, 1997, 1996, 24665, 23052, 2012, 10223, 26371, 1010, 2605, 2073, 1996, 6261, 2984, 22353, 2135, 2596, 2000, 3002, 16595, 9648, 4674, 2061, 12083, 9711, 2271, 1999, 8517, 1012, 2012, 1996, 2203, 1997, 1996, 2364, 3298, 1006, 1998, 1999, 1037, 3622, 2240, 2008, 8539, 2083, 1017, 11342, 1998, 1996, 2751, 8514, 1007, 1010, 2003, 1037, 3722, 1010, 2715, 2962, 6231, 1997, 2984, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_features[1].input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_features[1].input_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_features[1].segment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 56)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features[1].start_position, train_features[1].end_position"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
